---
title: 'Using NotebookLM for reading research papers'
date: 2025-03-04
draft: false
tags: ['howto', 'tools', 'efficiency']
---

Recently, I talked to my friend and was surprised that he was not aware of [NotebookLM](https://notebooklm.google.com/) by Google. Hence decided to write this brief note describing how I use it.

NotebookLM is a service developed by Google allowing you to interactively analyze any documents using LLM. An interactive personal RAG at your hand. The emphasis here is on interactivity. You basically chat with your document. You ask questions and the LLM provides you with answers.

The flow is as simple as:

1. Upload your document(s)
2. Wait for it to be processes
3. Start chatting with the LLM asking particular questions
4. Add additional documents/notes if needed

The tool is really cool and simple to use. It allows you to quickly summarize pretty long and dry documents, or extract certain details by asking questions that interest you. The list of use cases is really endless.

In my opinion, the key feature here is interactivity. The LLMs are a very powerful tool but the quality of their answers will correspond to the quality of your questions. If you ask a generic on-the-surface question, you will get a corresponding answer: generic and maybe too abstract. Interactivity enable you to overcome this limitation and get as deep needed. Sometimes, you will realize that an LLM has some knowledge gap and you have to upload additional documents to allow it to answer your questions more precisely.

I personally used it a couple of times to cross-validate my understanding of some contracts and even a mortgage. It does a great job of finding details of interest in a multi-page document and providing additional relevant context.

But my main use case today is "reading" ML papers. I admit, reading maybe an overstatement here. The proper words are familiarizing myself with these papers. Nevertheless, it is super helpful.

Another cool feature of NotebookLM is Audio Overview. You can create a short podcast-like overview of the uploaded documents. Then just listen to it as you walk, wash your dishes or just drive somewhere.

The audio is typically around 13 minutes. Sometimes as short as 10 minutes but sometimes can be as long as 25 minutes. The content is very alive and feels very natural, a pure joy to listen to: two persons discuss the paper debating with each other. The whole conversation feels very natural: the "debators" express emotions and change their intonations appropriately. So it is not too dry and easy to follow.

The main downside of this approach is that the content is still generated by the same LLMs. As a result, the discussion is sometimes does not go deep enough or is filled with too much "water". But that can be overcome as well by providing a mini-prompt to drive the audio dialogue.

My approach for reading ML papers is as follows:

1. Upload a single paper
2. Wait for it to be processes
3. Generate audio using the following prompt:

   ```
   This is a research paper:
   - Provide some background on the topic
   - Explain the proposed approach: what problem it solves, how and why it works
   - Explain the novelty in this paper (if any)
   - Explain the known limitations of the approach and weak points of the paper (if any)
   - Explain implications in practical applications of the approach
   - Explain academic implications of this paper, and future research
   
   Audience is experienced Software Developers (10y+) with good understanding of AI/ML basics.
   ```

I've been using it on a daily basis for "reading" interesting ML papers for the last year or so. And it's been a great instrument in my tool box for keeping myself aware of the recent trends. Of course, this does not replace reading the papers completely. When I find something interesting that I am capable of understanding, I would go and read the paper in depth.

I love the tool for:

1. allowing me to stay aware of the recent trends
2. getting a high-level understanding of papers that I would never be able to read by myself

I hope you find it useful as well!
